ENd to End Pipeline project steps:


Boiler plate Template:

# 1. Load data
# 2. Preprocess (encode, scale)
# 3. Train/test split
# 4. Train model(s)
# 5. Evaluate

ml_project/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ data.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ processed.csv
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model_<name>.pkl
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ params.yaml
â”œâ”€â”€ pipeline.py        â† (to run full flow)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


ğŸ§¾ Project Structure Guide (for README.md)
ğŸ“ 1. param.yaml
Configuration file to store all file paths and parameters in one place.


Code:

data:
  raw_path: data/raw/data.csv
  processed_path: data/processed/processed.csv

preprocess:
  encode_target: True
  scale: True

train:
  test_size: 0.2
  random_state: 42
  models: ["logistic", "knn", "decisiontree"]

evaluate:
  metrics_path: reports/metrics.json
